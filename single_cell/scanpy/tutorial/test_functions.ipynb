{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import numba\n",
    "\n",
    "# install dask if available\n",
    "try:\n",
    "    import dask.array as da\n",
    "except ImportError:\n",
    "    da = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_get_mean_var(X, axis=0):\n",
    "    if isinstance(X, sparse.spmatrix):  # same as sparse.issparse()\n",
    "        mean, var = my_sparse_mean_variance_axis(X, axis=axis)\n",
    "        var *= X.shape[axis] / (X.shape[axis] - 1)\n",
    "    else:\n",
    "        mean = np.mean(X, axis=axis)\n",
    "        mean_sq = np.var(X, axis=axis, ddof=1)  # a little overhead (mean counted twice, but it's ok.)\n",
    "    return mean, var\n",
    "'''\n",
    "In standard statistical practice, ddof=1 provides an unbiased estimator of the variance\n",
    "of a hypothetical infinite population. ddof=0 provides a maximum likelihood estimate of\n",
    "the variance for normally distributed variables.\n",
    "'''\n",
    "\n",
    "\n",
    "def my_sparse_mean_variance_axis(mtx: sparse.spmatrix, axis: int):\n",
    "    if isinstance(mtx, sparse.csr_matrix):\n",
    "        ax_minor = 1\n",
    "        shape = mtx.shape\n",
    "    elif isinstance(mtx, sparse.csc_matrix):\n",
    "        ax_minor = 0\n",
    "        shape = mtx.shape[::-1]\n",
    "    else:\n",
    "        raise ValueError('This function only works on sparse csr and csc matrices')\n",
    "    if axis == ax_minor:\n",
    "        print(1)\n",
    "        return my_sparse_mean_var_major_axis(\n",
    "            mtx.data, mtx.indices, mtx.indptr, *shape, np.float64\n",
    "        )\n",
    "    else:\n",
    "        print(0)\n",
    "        return my_sparse_mean_var_minor_axis(\n",
    "            mtx.data, mtx.indices, *shape, np.float64\n",
    "        )\n",
    "    \n",
    "\n",
    "def my_sparse_mean_var_major_axis(\n",
    "    data,\n",
    "    indices,\n",
    "    indptr,\n",
    "    major_len,\n",
    "    minor_len,\n",
    "    dtype\n",
    "):\n",
    "    means = np.zeros(major_len, dtype=dtype)\n",
    "    variances = np.zeros_like(means, dtype=dtype)  # why use zeros_like?\n",
    "    for ind, (startptr, endptr) in enumerate(zip(indptr[:-1], indptr[1:])):\n",
    "        counts = endptr - startptr\n",
    "        \n",
    "        mean = sum(data[startptr:endptr])\n",
    "        variance = sum((i-means[i]) ** 2 for i in data[startptr:endptr]) + mean ** 2 * (minor_len - counts)\n",
    "        means[ind] = mean / minor_len\n",
    "        variances[ind] = variance / minor_len\n",
    "        \n",
    "    return means, variances\n",
    "\n",
    "\n",
    "def my_sparse_mean_var_minor_axis(\n",
    "    data,\n",
    "    indices,\n",
    "    major_len,\n",
    "    minor_len,\n",
    "    dtype\n",
    "):\n",
    "    non_zero = indices.shape[0] # same as len(indices)?\n",
    "\n",
    "    means = np.zeros(minor_len, dtype=dtype)\n",
    "    variances = np.zeros_like(means, dtype=dtype)\n",
    "\n",
    "    counts = np.zeros(minor_len, dtype=np.int64)\n",
    "    \n",
    "    for ind, num in zip(indices, data):\n",
    "        means[ind] += num\n",
    "    \n",
    "    means /= major_len\n",
    "    \n",
    "    for ind, num in zip(indices, data):\n",
    "        variance[ind] += (num - means[ind]) ** 2\n",
    "        count[ind] += 1\n",
    "    print(variances)\n",
    "        \n",
    "    variances += [mean ** 2 * (major_len - count) for mean, count in zip(means, counts)]\n",
    "    variances /= major_len\n",
    "    \n",
    "    return means, variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_var(X, *, axis=0):\n",
    "    if sparse.issparse(X):\n",
    "        mean, var = sparse_mean_variance_axis(X, axis=axis)\n",
    "    else:\n",
    "        mean = np.mean(X, axis=axis, dtype=np.float64)\n",
    "        mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64)\n",
    "        var = mean_sq - mean ** 2\n",
    "    # enforce R convention (unbiased estimator) for variance\n",
    "    var *= X.shape[axis] / (X.shape[axis] - 1)\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def sparse_mean_variance_axis(mtx: sparse.spmatrix, axis: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This code and internal functions are based on sklearns\n",
    "    `sparsefuncs.mean_variance_axis`.\n",
    "    Modifications:\n",
    "    * allow deciding on the output type, which can increase accuracy when calculating the mean and variance of 32bit floats.\n",
    "    * This doesn't currently implement support for null values, but could.\n",
    "    * Uses numba not cython\n",
    "    \"\"\"\n",
    "    assert axis in (0, 1)\n",
    "    if isinstance(mtx, sparse.csr_matrix):\n",
    "        ax_minor = 1\n",
    "        shape = mtx.shape\n",
    "    elif isinstance(mtx, sparse.csc_matrix):\n",
    "        ax_minor = 0\n",
    "        shape = mtx.shape[::-1]\n",
    "    else:\n",
    "        raise ValueError(\"This function only works on sparse csr and csc matrices\")\n",
    "    if axis == ax_minor:\n",
    "        return sparse_mean_var_major_axis(\n",
    "            mtx.data, mtx.indices, mtx.indptr, *shape, np.float64\n",
    "        )\n",
    "    else:\n",
    "        return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64)\n",
    "\n",
    "\n",
    "@numba.njit(cache=True)\n",
    "def sparse_mean_var_minor_axis(\n",
    "    data,\n",
    "    indices,\n",
    "    major_len,\n",
    "    minor_len,\n",
    "    dtype\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes mean and variance for a sparse matrix for the minor axis.\n",
    "    Given arrays for a csr matrix, returns the means and variances for each\n",
    "    column back.\n",
    "    \"\"\"\n",
    "    non_zero = indices.shape[0]\n",
    "\n",
    "    means = np.zeros(minor_len, dtype=dtype)\n",
    "    variances = np.zeros_like(means, dtype=dtype)\n",
    "\n",
    "    counts = np.zeros(minor_len, dtype=np.int64)\n",
    "\n",
    "    for i in range(non_zero):\n",
    "        col_ind = indices[i]\n",
    "        means[col_ind] += data[i]\n",
    "\n",
    "    for i in range(minor_len):\n",
    "        means[i] /= major_len\n",
    "\n",
    "    for i in range(non_zero):\n",
    "        col_ind = indices[i]\n",
    "        diff = data[i] - means[col_ind]\n",
    "        variances[col_ind] += diff * diff\n",
    "        counts[col_ind] += 1\n",
    "    print(variances)\n",
    "    for i in range(minor_len):\n",
    "        variances[i] += (major_len - counts[i]) * means[i] ** 2\n",
    "        variances[i] /= major_len\n",
    "\n",
    "    return means, variances\n",
    "\n",
    "\n",
    "@numba.njit(cache=True)\n",
    "def sparse_mean_var_major_axis(\n",
    "    data,\n",
    "    indices,\n",
    "    indptr,\n",
    "    major_len,\n",
    "    minor_len,\n",
    "    dtype\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes mean and variance for a sparse array for the major axis.\n",
    "    Given arrays for a csr matrix, returns the means and variances for each\n",
    "    row back.\n",
    "    \"\"\"\n",
    "    means = np.zeros(major_len, dtype=dtype)\n",
    "    variances = np.zeros_like(means, dtype=dtype)\n",
    "\n",
    "    for i in range(major_len):\n",
    "        startptr = indptr[i]\n",
    "        endptr = indptr[i + 1]\n",
    "        counts = endptr - startptr\n",
    "\n",
    "        for j in range(startptr, endptr):\n",
    "            means[i] += data[j]\n",
    "        means[i] /= minor_len\n",
    "\n",
    "        for j in range(startptr, endptr):\n",
    "            diff = data[j] - means[i]\n",
    "            variances[i] += diff * diff\n",
    "\n",
    "        variances[i] += (minor_len - counts) * means[i] ** 2\n",
    "        variances[i] /= minor_len\n",
    "\n",
    "    return means, variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def materialize_as_ndarray(a):\n",
    "    \"\"\"Convert distributed arrays to ndarrays.\"\"\"\n",
    "    if type(a) in (list, tuple):\n",
    "        if da is not None and any(isinstance(arr, da.Array) for arr in a):\n",
    "            return da.compute(*a, sync=True)\n",
    "        return tuple(np.asarray(arr) for arr in a)\n",
    "    return np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr = np.array([0, 2, 3, 6])\n",
    "indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "b = sparse.csr_matrix((data, indices, indptr), shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 5.88888889 11.11111111  8.66666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.66666667, 1.66666667, 3.66666667]),\n",
       " array([4.33333333, 8.33333333, 4.33333333]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_get_mean_var(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.88888889 11.11111111  8.66666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.66666667, 1.66666667, 3.66666667]),\n",
       " array([4.33333333, 8.33333333, 4.33333333]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_var(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 5.88888889 11.11111111  8.66666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.66666667, 1.66666667, 3.66666667]),\n",
       " array([2.88888889, 5.55555556, 2.88888889]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sparse_mean_variance_axis(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.88888889 11.11111111  8.66666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.66666667, 1.66666667, 3.66666667]),\n",
       " array([2.88888889, 5.55555556, 2.88888889]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mean_variance_axis(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4.33333333, 8.33333333, 4.33333333]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(b.todense(), axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
